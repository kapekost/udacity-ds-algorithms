## Problem 1

First step was to add a dictionary for the items to cache
- the items should never be duplicated, and the access to the dictionary is efficient
- enqueue and dequeue function to manage the state of the queue 
this allows us to change the type/logic of caching, just by simply adjusting the queue/dequeue functions

- we want to keep the most recently accessed element in the cache, 
for this reason I thought to start aligning the order within the queue swapping items
but that would increase the Complexity. Accessing an item should remove that item from the queue and 
put it back first. The access will be random. Therefore this solution would be very complex 

I found good idea to keep an array of keys separate to hold the order (access priority swap). 
since the queue is a dictionary (Set) it doesn't hold duplicates already. The list of keys 
can be a simple array that has index(order)
so in case of a get() the only addition in the logic would be to remove an existing key from this new list_f_keys,
and push to the first place the same new value. Instead of managing swaps
```      
if(index in self.list_of_keys):
    self.list_of_keys.remove(index)
self.list_of_keys.append(index)
```

Space

- for the dictionary, which can get as many as the capacity, and the key:values that it holds.
in our current samples it holds values as integers.
- for the array of the keys, again same size as the capacity and integers for single values


Complexity 

- dequeue:
O(n) for both removing the key form the array and the object from the Cache Set
Complexity => O(n)

- enqueue
we add a value in the Set (O(1))
if we find a key in the list of keys, we remove it (O(n)) 
and then (+)
we append the index in the list of keys (O(n))
Complexity => O(n)

- get
we do a lookup O(n) and if we hit a result we do an enqueue (O(n)) for that one value
Complexity => O(n)

- index
just reassigns and returns the value
Complexity => O(1)

- set
performs a get(), O(n)
in case of a miss we do either an enqueue() (O(n)) or dequeue() (O(n)) followed by a set() (O(n))
Complexity => O(n)


## Problem 2

Starting from the root directory(where the program runs) we look for the given folder

print(f"c files: {file_explorer.find_files('.c', 'testdir')}")

for that directory we:
- loop through the listed files:
    for each file: (O(1))
    - if it's a file we check the suffix (string lookup) (O(1))
    - add in list (O(1))
    for each folder: (O(1))
    - if it's a folder we call this function again [recursive] (O(n))

Space:
    we use
    - a list for the files we find in a directory (+ subdirectories)
    - a smaller list for the results (files we were looking for)

Complexity:
worst case would be all the items in the directories to be sub-directories
for n depth we would be going through all of them.

Complexity => O(n)


## Problem 3

# Huffman Encoding

The process is split in functions based on the steps we need to take to encode and decode a string
Space complexity:
- we use Nodes that hold 2 child nodes, a value and a character. 
The number of nodes depends on the unique characters of the string we are Encoding
For the steps in the process, we use:
step 1
 - an array of frequencies, 
 - a dictionary for the count of the frequency of the letters
 - an array for the nodes we want to start merging
while we merge, we use a new node, and we eliminate 2 other each time

For the huffman_code we use a dictionary for the table we want to return, 
and an array for the current path calculation

for the encoding we use a string that we append the characters

Time complexity:
- get frequency nodes:
    - loop though the characters in the string (O(n))
    - create an array of tuples with the count of each letter (O(1))
    - sort the tuples based on frequency O(n log n)
    - loop through the tuples and create Nodes for all of them (O(m)) m is the amount of unique letters (tuples)
    return the array of nodes
O(n log(n))

- pass the nodes to merge_min_nodes until we are left with one root nodes
    for m unique letters of the string we will run this process m times (O(m^2)) 
        (because in each step we need to sort again)
    - in every recursion we pick the first 2 nodes and create a new tree
    - loop through the remaining nodes to add them in the new tree to return
O(m^2)

- Using the tree we just created, we can navigate to the leafs, which hold the letters
    The path to the leaf is the one we need to use to represent the letter that lives in the leaf
    Since the tree is balanced binary tree, the process will have complexity:
 O(log(n))

 - Last step is to loop through the letters we want to encode and replace them with the binary representation 
  that we got from the previous step, respectively
  O(n) n is the size of the string we want to encode

O(n log(n)) + O(m^2) +  O(log(n)) +  O(n) if all the letters are different m == n

  Complexity => O(n^2)

# Decoding Huffman

input is the encoded string, and the tree of nodes with leafs to be the letter we want to find

for space we don't use anything extra

Time Complexity:

for each bit (n) in the string, we navigate in the tree.
  
  Complexity => O(n)

